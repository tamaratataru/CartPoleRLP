{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning (Final Assignment)\n",
    "#### Team 29\n",
    "#### Kees Wierenga\n",
    "#### Tamara Tataru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment - Taxi-v3\n",
    "### Q-Learning Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Q-Table and count array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_Q_table(env):\n",
    "    \"\"\"\n",
    "    For the given environment, the possible actions are integers from 0-5, \n",
    "    and the possible states are integers from 0-499.\n",
    "    Therefore, the Q-Value of, for example, taking action 3 in state 156 can be found as Q[156, 3]\n",
    "    \"\"\"\n",
    "\n",
    "    return np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "def init_count_arary(env):\n",
    "    return np.zeros([env.observation_space.n, env.action_space.n])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define UCB policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_UCB_action(Q, state, N, env, step, c):\n",
    "    argMax = 0 \n",
    "    iMax = 0 \n",
    "    for i in range (env.env.action_space.n):\n",
    "        if N[state, i] == 0 or step ==0:\n",
    "            temp = float('inf')\n",
    "        else:         \n",
    "            temp = Q[state, i] + (c * np.sqrt(np.log(step) / N[state, i]))\n",
    "        if temp > argMax:\n",
    "            iMax = i\n",
    "            argMax = temp\n",
    "    N[state, iMax] = N[state,iMax] + 1 \n",
    "    return iMax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define steps to follow by agent during an episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_episode(Q, N, max_timesteps, c):\n",
    "    \n",
    "    # Initialize Rewards historic\n",
    "    rewards = list()\n",
    "    \n",
    "    # Reset environment\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    for s in range(max_timesteps):\n",
    "        \n",
    "        # Pick action following epsilon-greedy policy\n",
    "        action = get_UCB_action(Q, state,N, env, s, c )\n",
    "        \n",
    "        # Perform action and receive new state S' and reward R\n",
    "        new_state, reward, done, info, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        # Update Q-values \n",
    "        old_value = Q[state, action]\n",
    "        next_max = np.max(Q[new_state])\n",
    "        new_value = (1 - step_size)*old_value + step_size*(reward + discount_factor * next_max)\n",
    "        Q[state, action] = new_value\n",
    "        \n",
    "        state = new_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "      \n",
    "    return Q, sum(rewards)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.05\n",
    "discount_factor = 0.9\n",
    "n_episodes = 60000\n",
    "n_steps = 500\n",
    "\n",
    "env = gym.make('Taxi-v3').env\n",
    "rewards_history = list()\n",
    "\n",
    "def train_q_learning(c):\n",
    "    \n",
    "    Q = initialize_Q_table(env)\n",
    "    N = init_count_arary(env)\n",
    "    for episode in range(n_episodes):\n",
    "        print(f'Training on Episode {episode+1}... c: {c}', end=\"\\r\")\n",
    "\n",
    "        Q, reward = execute_episode(Q, N, n_steps, c)\n",
    "        \n",
    "        rewards_history.append(reward)\n",
    "        \n",
    "    return Q, rewards_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Episode 60000... c: 10\r"
     ]
    }
   ],
   "source": [
    "trained_Q, rewards_history = train_q_learning(10)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Agent's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewards history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(n_episodes), rewards_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_episodes_on_trained_agent(Q, n_episodes):\n",
    "    \n",
    "    episode_rewards = dict()\n",
    "    for episode in range(n_episodes):\n",
    "        print(f'Executing Episode {episode+1}...')\n",
    "        \n",
    "        # Initialize historics\n",
    "        rewards = list()\n",
    "\n",
    "        state, _ = env.reset()\n",
    "\n",
    "        done = False\n",
    "        n_steps = 0\n",
    "\n",
    "        while not done and n_steps < 100:\n",
    "\n",
    "            action = np.argmax(Q[state])\n",
    "\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            n_steps += 1\n",
    "            \n",
    "        episode_rewards[episode] = (sum(rewards), n_steps)\n",
    "        print(f'Episode {episode+1} took {n_steps} steps, and got a reward of {sum(rewards)}\\n')\n",
    "\n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Episode 1...\n",
      "Episode 1 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 2...\n",
      "Episode 2 took 13 steps, and got a reward of 8\n",
      "\n",
      "Executing Episode 3...\n",
      "Episode 3 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 4...\n",
      "Episode 4 took 17 steps, and got a reward of 4\n",
      "\n",
      "Executing Episode 5...\n",
      "Episode 5 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 6...\n",
      "Episode 6 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 7...\n",
      "Episode 7 took 10 steps, and got a reward of 11\n",
      "\n",
      "Executing Episode 8...\n",
      "Episode 8 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 9...\n",
      "Episode 9 took 100 steps, and got a reward of -100\n",
      "\n",
      "Executing Episode 10...\n",
      "Episode 10 took 100 steps, and got a reward of -100\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average number of timesteps per episode:  74.0\n",
      "Average reward per episode:  -67.7\n"
     ]
    }
   ],
   "source": [
    "n_test_episodes = 10\n",
    "trained_agent_rewards = execute_episodes_on_trained_agent(trained_Q, n_test_episodes)\n",
    "\n",
    "avg_steps = sum([episode_info[1] for episode_info in trained_agent_rewards.values()])/n_test_episodes\n",
    "avg_reward = sum([episode_info[0] for episode_info in trained_agent_rewards.values()])/n_test_episodes\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Average number of timesteps per episode: ', avg_steps)\n",
    "print('Average reward per episode: ', avg_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "116bfafb5e177d7c9f89e6c9a94801bbad54c54467ca278ddb9cf43bc194b7c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
